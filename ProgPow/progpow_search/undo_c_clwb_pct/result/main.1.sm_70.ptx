







.version 6.4
.target sm_70
.address_size 64


.const .align 4 .b8 keccakf_rndc[96] = {1, 0, 0, 0, 130, 128, 0, 0, 138, 128, 0, 0, 0, 128, 0, 128, 139, 128, 0, 0, 1, 0, 0, 128, 129, 128, 0, 128, 9, 128, 0, 0, 138, 0, 0, 0, 136, 0, 0, 0, 9, 128, 0, 128, 10, 0, 0, 128, 139, 128, 0, 128, 139, 0, 0, 0, 137, 128, 0, 0, 3, 128, 0, 0, 2, 128, 0, 0, 128, 0, 0, 0, 10, 128, 0, 0, 10, 0, 0, 128, 129, 128, 0, 128, 128, 128, 0, 0, 1, 0, 0, 128, 8, 128, 0, 128};
.global .align 4 .b8 NVM_log[67108864];
.global .align 4 .b8 NVM_flag[4194304];


.visible .entry _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb(
.param .u64 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_0,
.param .align 16 .b8 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_1[32],
.param .u64 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_2,
.param .u64 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_3,
.param .u64 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_4,
.param .u8 _Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_5
)
{
.reg .pred %p<32>;
.reg .b16 %rs<3>;
.reg .f32 %f<4>;
.reg .b32 %r<1379>;
.reg .b64 %rd<60>;

	.shared .align 4 .b8 _ZZ14progpow_searchm8hash32_tmPK5dag_tP14search_resultsbE5c_dag[16384];

ld.param.u64 %rd7, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_3];
ld.param.s8 %rs1, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_5];
cvta.to.global.u64 %rd1, %rd7;
mov.u32 %r1, %ntid.x;
mov.u32 %r3, %tid.x;
and.b32 %r4, %r3, 15;
shl.b32 %r1263, %r3, 2;
setp.gt.u32	%p2, %r1263, 4095;
@%p2 bra BB0_3;

shl.b32 %r6, %r1, 2;

BB0_2:
shr.u32 %r243, %r1263, 2;
mul.wide.u32 %rd8, %r243, 16;
add.s64 %rd9, %rd1, %rd8;
ld.global.v4.u32 {%r244, %r245, %r246, %r247}, [%rd9];
shl.b32 %r252, %r1263, 2;
mov.u32 %r253, _ZZ14progpow_searchm8hash32_tmPK5dag_tP14search_resultsbE5c_dag;
add.s32 %r254, %r253, %r252;
st.shared.u32 [%r254], %r244;
st.shared.u32 [%r254+4], %r245;
st.shared.u32 [%r254+8], %r246;
st.shared.u32 [%r254+12], %r247;
add.s32 %r1263, %r1263, %r6;
setp.lt.u32	%p3, %r1263, 4096;
@%p3 bra BB0_2;

BB0_3:
bar.sync 0;
mov.u32 %r263, 0;
and.b16 %rs2, %rs1, 255;
mov.u32 %r1371, %r263;
mov.u32 %r1372, %r263;
mov.u32 %r1373, %r263;
mov.u32 %r1374, %r263;
mov.u32 %r1375, %r263;
mov.u32 %r1376, %r263;
mov.u32 %r1377, %r263;
mov.u32 %r1378, %r263;
mov.u32 %r1272, %r263;

BB0_4:
.pragma "nounroll";
mov.u64 %rd10, 0;

	mov.b64 {%r264,%r265}, %rd10;

	mov.u32 %r270, 4127;
mov.u32 %r271, -1;
shfl.sync.idx.b32 %r267|%p4, %r265, %r1272, %r270, %r271;
shfl.sync.idx.b32 %r266|%p5, %r264, %r1272, %r270, %r271;

	mov.b64 %rd11, {%r266,%r267};

	cvt.u32.u64	%r272, %rd11;
xor.b32 %r273, %r272, -2128831035;
mul.lo.s32 %r274, %r273, 16777619;
shr.u64 %rd12, %rd11, 32;
cvt.u32.u64	%r275, %rd12;
xor.b32 %r276, %r274, %r275;
mul.lo.s32 %r277, %r276, 16777619;
xor.b32 %r278, %r277, %r4;
mul.lo.s32 %r279, %r278, 16777619;
xor.b32 %r280, %r279, %r4;
and.b32 %r281, %r274, 65535;
shr.u32 %r282, %r274, 16;
mad.lo.s32 %r283, %r281, 36969, %r282;
and.b32 %r284, %r277, 65535;
shr.u32 %r285, %r277, 16;
mad.lo.s32 %r286, %r284, 18000, %r285;
shl.b32 %r287, %r283, 16;
add.s32 %r288, %r287, %r286;
mul.lo.s32 %r289, %r278, 52822016;
xor.b32 %r290, %r289, %r279;
shr.u32 %r291, %r290, 13;
xor.b32 %r292, %r291, %r290;
shl.b32 %r293, %r292, 5;
xor.b32 %r294, %r293, %r292;
mad.lo.s32 %r295, %r280, -827803209, 1234567;
xor.b32 %r296, %r288, %r295;
add.s32 %r1339, %r294, %r296;
and.b32 %r297, %r283, 65535;
shr.u32 %r298, %r283, 16;
mad.lo.s32 %r299, %r297, 36969, %r298;
and.b32 %r300, %r286, 65535;
shr.u32 %r301, %r286, 16;
mad.lo.s32 %r302, %r300, 18000, %r301;
shl.b32 %r303, %r299, 16;
add.s32 %r304, %r303, %r302;
shl.b32 %r305, %r294, 17;
xor.b32 %r306, %r305, %r294;
shr.u32 %r307, %r306, 13;
xor.b32 %r308, %r307, %r306;
shl.b32 %r309, %r308, 5;
xor.b32 %r310, %r309, %r308;
mad.lo.s32 %r311, %r295, 69069, 1234567;
xor.b32 %r312, %r304, %r311;
add.s32 %r1351, %r310, %r312;
and.b32 %r313, %r299, 65535;
shr.u32 %r314, %r299, 16;
mad.lo.s32 %r315, %r313, 36969, %r314;
and.b32 %r316, %r302, 65535;
shr.u32 %r317, %r302, 16;
mad.lo.s32 %r318, %r316, 18000, %r317;
shl.b32 %r319, %r315, 16;
add.s32 %r320, %r319, %r318;
shl.b32 %r321, %r310, 17;
xor.b32 %r322, %r321, %r310;
shr.u32 %r323, %r322, 13;
xor.b32 %r324, %r323, %r322;
shl.b32 %r325, %r324, 5;
xor.b32 %r326, %r325, %r324;
mad.lo.s32 %r327, %r311, 69069, 1234567;
xor.b32 %r328, %r320, %r327;
add.s32 %r1343, %r326, %r328;
and.b32 %r329, %r315, 65535;
shr.u32 %r330, %r315, 16;
mad.lo.s32 %r331, %r329, 36969, %r330;
and.b32 %r332, %r318, 65535;
shr.u32 %r333, %r318, 16;
mad.lo.s32 %r334, %r332, 18000, %r333;
shl.b32 %r335, %r331, 16;
add.s32 %r336, %r335, %r334;
shl.b32 %r337, %r326, 17;
xor.b32 %r338, %r337, %r326;
shr.u32 %r339, %r338, 13;
xor.b32 %r340, %r339, %r338;
shl.b32 %r341, %r340, 5;
xor.b32 %r342, %r341, %r340;
mad.lo.s32 %r343, %r327, 69069, 1234567;
xor.b32 %r344, %r336, %r343;
add.s32 %r1346, %r342, %r344;
and.b32 %r345, %r331, 65535;
shr.u32 %r346, %r331, 16;
mad.lo.s32 %r347, %r345, 36969, %r346;
and.b32 %r348, %r334, 65535;
shr.u32 %r349, %r334, 16;
mad.lo.s32 %r350, %r348, 18000, %r349;
shl.b32 %r351, %r347, 16;
add.s32 %r352, %r351, %r350;
shl.b32 %r353, %r342, 17;
xor.b32 %r354, %r353, %r342;
shr.u32 %r355, %r354, 13;
xor.b32 %r356, %r355, %r354;
shl.b32 %r357, %r356, 5;
xor.b32 %r358, %r357, %r356;
mad.lo.s32 %r359, %r343, 69069, 1234567;
xor.b32 %r360, %r352, %r359;
add.s32 %r1341, %r358, %r360;
and.b32 %r361, %r347, 65535;
shr.u32 %r362, %r347, 16;
mad.lo.s32 %r363, %r361, 36969, %r362;
and.b32 %r364, %r350, 65535;
shr.u32 %r365, %r350, 16;
mad.lo.s32 %r366, %r364, 18000, %r365;
shl.b32 %r367, %r363, 16;
add.s32 %r368, %r367, %r366;
shl.b32 %r369, %r358, 17;
xor.b32 %r370, %r369, %r358;
shr.u32 %r371, %r370, 13;
xor.b32 %r372, %r371, %r370;
shl.b32 %r373, %r372, 5;
xor.b32 %r374, %r373, %r372;
mad.lo.s32 %r375, %r359, 69069, 1234567;
xor.b32 %r376, %r368, %r375;
add.s32 %r1361, %r374, %r376;
and.b32 %r377, %r363, 65535;
shr.u32 %r378, %r363, 16;
mad.lo.s32 %r379, %r377, 36969, %r378;
and.b32 %r380, %r366, 65535;
shr.u32 %r381, %r366, 16;
mad.lo.s32 %r382, %r380, 18000, %r381;
shl.b32 %r383, %r379, 16;
add.s32 %r384, %r383, %r382;
shl.b32 %r385, %r374, 17;
xor.b32 %r386, %r385, %r374;
shr.u32 %r387, %r386, 13;
xor.b32 %r388, %r387, %r386;
shl.b32 %r389, %r388, 5;
xor.b32 %r390, %r389, %r388;
mad.lo.s32 %r391, %r375, 69069, 1234567;
xor.b32 %r392, %r384, %r391;
add.s32 %r1356, %r390, %r392;
and.b32 %r393, %r379, 65535;
shr.u32 %r394, %r379, 16;
mad.lo.s32 %r395, %r393, 36969, %r394;
and.b32 %r396, %r382, 65535;
shr.u32 %r397, %r382, 16;
mad.lo.s32 %r398, %r396, 18000, %r397;
shl.b32 %r399, %r395, 16;
add.s32 %r400, %r399, %r398;
shl.b32 %r401, %r390, 17;
xor.b32 %r402, %r401, %r390;
shr.u32 %r403, %r402, 13;
xor.b32 %r404, %r403, %r402;
shl.b32 %r405, %r404, 5;
xor.b32 %r406, %r405, %r404;
mad.lo.s32 %r407, %r391, 69069, 1234567;
xor.b32 %r408, %r400, %r407;
add.s32 %r1364, %r406, %r408;
and.b32 %r409, %r395, 65535;
shr.u32 %r410, %r395, 16;
mad.lo.s32 %r411, %r409, 36969, %r410;
and.b32 %r412, %r398, 65535;
shr.u32 %r413, %r398, 16;
mad.lo.s32 %r414, %r412, 18000, %r413;
shl.b32 %r415, %r411, 16;
add.s32 %r416, %r415, %r414;
shl.b32 %r417, %r406, 17;
xor.b32 %r418, %r417, %r406;
shr.u32 %r419, %r418, 13;
xor.b32 %r420, %r419, %r418;
shl.b32 %r421, %r420, 5;
xor.b32 %r422, %r421, %r420;
mad.lo.s32 %r423, %r407, 69069, 1234567;
xor.b32 %r424, %r416, %r423;
add.s32 %r1347, %r422, %r424;
and.b32 %r425, %r411, 65535;
shr.u32 %r426, %r411, 16;
mad.lo.s32 %r427, %r425, 36969, %r426;
and.b32 %r428, %r414, 65535;
shr.u32 %r429, %r414, 16;
mad.lo.s32 %r430, %r428, 18000, %r429;
shl.b32 %r431, %r427, 16;
add.s32 %r432, %r431, %r430;
shl.b32 %r433, %r422, 17;
xor.b32 %r434, %r433, %r422;
shr.u32 %r435, %r434, 13;
xor.b32 %r436, %r435, %r434;
shl.b32 %r437, %r436, 5;
xor.b32 %r438, %r437, %r436;
mad.lo.s32 %r439, %r423, 69069, 1234567;
xor.b32 %r440, %r432, %r439;
add.s32 %r1369, %r438, %r440;
and.b32 %r441, %r427, 65535;
shr.u32 %r442, %r427, 16;
mad.lo.s32 %r443, %r441, 36969, %r442;
and.b32 %r444, %r430, 65535;
shr.u32 %r445, %r430, 16;
mad.lo.s32 %r446, %r444, 18000, %r445;
shl.b32 %r447, %r443, 16;
add.s32 %r448, %r447, %r446;
shl.b32 %r449, %r438, 17;
xor.b32 %r450, %r449, %r438;
shr.u32 %r451, %r450, 13;
xor.b32 %r452, %r451, %r450;
shl.b32 %r453, %r452, 5;
xor.b32 %r454, %r453, %r452;
mad.lo.s32 %r455, %r439, 69069, 1234567;
xor.b32 %r456, %r448, %r455;
add.s32 %r1357, %r454, %r456;
and.b32 %r457, %r443, 65535;
shr.u32 %r458, %r443, 16;
mad.lo.s32 %r459, %r457, 36969, %r458;
and.b32 %r460, %r446, 65535;
shr.u32 %r461, %r446, 16;
mad.lo.s32 %r462, %r460, 18000, %r461;
shl.b32 %r463, %r459, 16;
add.s32 %r464, %r463, %r462;
shl.b32 %r465, %r454, 17;
xor.b32 %r466, %r465, %r454;
shr.u32 %r467, %r466, 13;
xor.b32 %r468, %r467, %r466;
shl.b32 %r469, %r468, 5;
xor.b32 %r470, %r469, %r468;
mad.lo.s32 %r471, %r455, 69069, 1234567;
xor.b32 %r472, %r464, %r471;
add.s32 %r1360, %r470, %r472;
and.b32 %r473, %r459, 65535;
shr.u32 %r474, %r459, 16;
mad.lo.s32 %r475, %r473, 36969, %r474;
and.b32 %r476, %r462, 65535;
shr.u32 %r477, %r462, 16;
mad.lo.s32 %r478, %r476, 18000, %r477;
shl.b32 %r479, %r475, 16;
add.s32 %r480, %r479, %r478;
shl.b32 %r481, %r470, 17;
xor.b32 %r482, %r481, %r470;
shr.u32 %r483, %r482, 13;
xor.b32 %r484, %r483, %r482;
shl.b32 %r485, %r484, 5;
xor.b32 %r486, %r485, %r484;
mad.lo.s32 %r487, %r471, 69069, 1234567;
xor.b32 %r488, %r480, %r487;
add.s32 %r1365, %r486, %r488;
and.b32 %r489, %r475, 65535;
shr.u32 %r490, %r475, 16;
mad.lo.s32 %r491, %r489, 36969, %r490;
and.b32 %r492, %r478, 65535;
shr.u32 %r493, %r478, 16;
mad.lo.s32 %r494, %r492, 18000, %r493;
shl.b32 %r495, %r491, 16;
add.s32 %r496, %r495, %r494;
shl.b32 %r497, %r486, 17;
xor.b32 %r498, %r497, %r486;
shr.u32 %r499, %r498, 13;
xor.b32 %r500, %r499, %r498;
shl.b32 %r501, %r500, 5;
xor.b32 %r502, %r501, %r500;
mad.lo.s32 %r503, %r487, 69069, 1234567;
xor.b32 %r504, %r496, %r503;
add.s32 %r1340, %r502, %r504;
and.b32 %r505, %r491, 65535;
shr.u32 %r506, %r491, 16;
mad.lo.s32 %r507, %r505, 36969, %r506;
and.b32 %r508, %r494, 65535;
shr.u32 %r509, %r494, 16;
mad.lo.s32 %r510, %r508, 18000, %r509;
shl.b32 %r511, %r507, 16;
add.s32 %r512, %r511, %r510;
shl.b32 %r513, %r502, 17;
xor.b32 %r514, %r513, %r502;
shr.u32 %r515, %r514, 13;
xor.b32 %r516, %r515, %r514;
shl.b32 %r517, %r516, 5;
xor.b32 %r518, %r517, %r516;
mad.lo.s32 %r519, %r503, 69069, 1234567;
xor.b32 %r520, %r512, %r519;
add.s32 %r1354, %r518, %r520;
and.b32 %r521, %r507, 65535;
shr.u32 %r522, %r507, 16;
mad.lo.s32 %r523, %r521, 36969, %r522;
and.b32 %r524, %r510, 65535;
shr.u32 %r525, %r510, 16;
mad.lo.s32 %r526, %r524, 18000, %r525;
shl.b32 %r527, %r523, 16;
add.s32 %r528, %r527, %r526;
shl.b32 %r529, %r518, 17;
xor.b32 %r530, %r529, %r518;
shr.u32 %r531, %r530, 13;
xor.b32 %r532, %r531, %r530;
shl.b32 %r533, %r532, 5;
xor.b32 %r534, %r533, %r532;
mad.lo.s32 %r535, %r519, 69069, 1234567;
xor.b32 %r536, %r528, %r535;
add.s32 %r1368, %r534, %r536;
and.b32 %r537, %r523, 65535;
shr.u32 %r538, %r523, 16;
mad.lo.s32 %r539, %r537, 36969, %r538;
and.b32 %r540, %r526, 65535;
shr.u32 %r541, %r526, 16;
mad.lo.s32 %r542, %r540, 18000, %r541;
shl.b32 %r543, %r539, 16;
add.s32 %r544, %r543, %r542;
shl.b32 %r545, %r534, 17;
xor.b32 %r546, %r545, %r534;
shr.u32 %r547, %r546, 13;
xor.b32 %r548, %r547, %r546;
shl.b32 %r549, %r548, 5;
xor.b32 %r550, %r549, %r548;
mad.lo.s32 %r551, %r535, 69069, 1234567;
xor.b32 %r552, %r544, %r551;
add.s32 %r1367, %r550, %r552;
and.b32 %r553, %r539, 65535;
shr.u32 %r554, %r539, 16;
mad.lo.s32 %r555, %r553, 36969, %r554;
and.b32 %r556, %r542, 65535;
shr.u32 %r557, %r542, 16;
mad.lo.s32 %r558, %r556, 18000, %r557;
shl.b32 %r559, %r555, 16;
add.s32 %r560, %r559, %r558;
shl.b32 %r561, %r550, 17;
xor.b32 %r562, %r561, %r550;
shr.u32 %r563, %r562, 13;
xor.b32 %r564, %r563, %r562;
shl.b32 %r565, %r564, 5;
xor.b32 %r566, %r565, %r564;
mad.lo.s32 %r567, %r551, 69069, 1234567;
xor.b32 %r568, %r560, %r567;
add.s32 %r1359, %r566, %r568;
and.b32 %r569, %r555, 65535;
shr.u32 %r570, %r555, 16;
mad.lo.s32 %r571, %r569, 36969, %r570;
and.b32 %r572, %r558, 65535;
shr.u32 %r573, %r558, 16;
mad.lo.s32 %r574, %r572, 18000, %r573;
shl.b32 %r575, %r571, 16;
add.s32 %r576, %r575, %r574;
shl.b32 %r577, %r566, 17;
xor.b32 %r578, %r577, %r566;
shr.u32 %r579, %r578, 13;
xor.b32 %r580, %r579, %r578;
shl.b32 %r581, %r580, 5;
xor.b32 %r582, %r581, %r580;
mad.lo.s32 %r583, %r567, 69069, 1234567;
xor.b32 %r584, %r576, %r583;
add.s32 %r1350, %r582, %r584;
and.b32 %r585, %r571, 65535;
shr.u32 %r586, %r571, 16;
mad.lo.s32 %r587, %r585, 36969, %r586;
and.b32 %r588, %r574, 65535;
shr.u32 %r589, %r574, 16;
mad.lo.s32 %r590, %r588, 18000, %r589;
shl.b32 %r591, %r587, 16;
add.s32 %r592, %r591, %r590;
shl.b32 %r593, %r582, 17;
xor.b32 %r594, %r593, %r582;
shr.u32 %r595, %r594, 13;
xor.b32 %r596, %r595, %r594;
shl.b32 %r597, %r596, 5;
xor.b32 %r598, %r597, %r596;
mad.lo.s32 %r599, %r583, 69069, 1234567;
xor.b32 %r600, %r592, %r599;
add.s32 %r1353, %r598, %r600;
and.b32 %r601, %r587, 65535;
shr.u32 %r602, %r587, 16;
mad.lo.s32 %r603, %r601, 36969, %r602;
and.b32 %r604, %r590, 65535;
shr.u32 %r605, %r590, 16;
mad.lo.s32 %r606, %r604, 18000, %r605;
shl.b32 %r607, %r603, 16;
add.s32 %r608, %r607, %r606;
shl.b32 %r609, %r598, 17;
xor.b32 %r610, %r609, %r598;
shr.u32 %r611, %r610, 13;
xor.b32 %r612, %r611, %r610;
shl.b32 %r613, %r612, 5;
xor.b32 %r614, %r613, %r612;
mad.lo.s32 %r615, %r599, 69069, 1234567;
xor.b32 %r616, %r608, %r615;
add.s32 %r1342, %r614, %r616;
and.b32 %r617, %r603, 65535;
shr.u32 %r618, %r603, 16;
mad.lo.s32 %r619, %r617, 36969, %r618;
and.b32 %r620, %r606, 65535;
shr.u32 %r621, %r606, 16;
mad.lo.s32 %r622, %r620, 18000, %r621;
shl.b32 %r623, %r619, 16;
add.s32 %r624, %r623, %r622;
shl.b32 %r625, %r614, 17;
xor.b32 %r626, %r625, %r614;
shr.u32 %r627, %r626, 13;
xor.b32 %r628, %r627, %r626;
shl.b32 %r629, %r628, 5;
xor.b32 %r630, %r629, %r628;
mad.lo.s32 %r631, %r615, 69069, 1234567;
xor.b32 %r632, %r624, %r631;
add.s32 %r1349, %r630, %r632;
and.b32 %r633, %r619, 65535;
shr.u32 %r634, %r619, 16;
mad.lo.s32 %r635, %r633, 36969, %r634;
and.b32 %r636, %r622, 65535;
shr.u32 %r637, %r622, 16;
mad.lo.s32 %r638, %r636, 18000, %r637;
shl.b32 %r639, %r635, 16;
add.s32 %r640, %r639, %r638;
shl.b32 %r641, %r630, 17;
xor.b32 %r642, %r641, %r630;
shr.u32 %r643, %r642, 13;
xor.b32 %r644, %r643, %r642;
shl.b32 %r645, %r644, 5;
xor.b32 %r646, %r645, %r644;
mad.lo.s32 %r647, %r631, 69069, 1234567;
xor.b32 %r648, %r640, %r647;
add.s32 %r1348, %r646, %r648;
and.b32 %r649, %r635, 65535;
shr.u32 %r650, %r635, 16;
mad.lo.s32 %r651, %r649, 36969, %r650;
and.b32 %r652, %r638, 65535;
shr.u32 %r653, %r638, 16;
mad.lo.s32 %r654, %r652, 18000, %r653;
shl.b32 %r655, %r651, 16;
add.s32 %r656, %r655, %r654;
shl.b32 %r657, %r646, 17;
xor.b32 %r658, %r657, %r646;
shr.u32 %r659, %r658, 13;
xor.b32 %r660, %r659, %r658;
shl.b32 %r661, %r660, 5;
xor.b32 %r662, %r661, %r660;
mad.lo.s32 %r663, %r647, 69069, 1234567;
xor.b32 %r664, %r656, %r663;
add.s32 %r1352, %r662, %r664;
and.b32 %r665, %r651, 65535;
shr.u32 %r666, %r651, 16;
mad.lo.s32 %r667, %r665, 36969, %r666;
and.b32 %r668, %r654, 65535;
shr.u32 %r669, %r654, 16;
mad.lo.s32 %r670, %r668, 18000, %r669;
shl.b32 %r671, %r667, 16;
add.s32 %r672, %r671, %r670;
shl.b32 %r673, %r662, 17;
xor.b32 %r674, %r673, %r662;
shr.u32 %r675, %r674, 13;
xor.b32 %r676, %r675, %r674;
shl.b32 %r677, %r676, 5;
xor.b32 %r678, %r677, %r676;
mad.lo.s32 %r679, %r663, 69069, 1234567;
xor.b32 %r680, %r672, %r679;
add.s32 %r1355, %r678, %r680;
and.b32 %r681, %r667, 65535;
shr.u32 %r682, %r667, 16;
mad.lo.s32 %r683, %r681, 36969, %r682;
and.b32 %r684, %r670, 65535;
shr.u32 %r685, %r670, 16;
mad.lo.s32 %r686, %r684, 18000, %r685;
shl.b32 %r687, %r683, 16;
add.s32 %r688, %r687, %r686;
shl.b32 %r689, %r678, 17;
xor.b32 %r690, %r689, %r678;
shr.u32 %r691, %r690, 13;
xor.b32 %r692, %r691, %r690;
shl.b32 %r693, %r692, 5;
xor.b32 %r694, %r693, %r692;
mad.lo.s32 %r695, %r679, 69069, 1234567;
xor.b32 %r696, %r688, %r695;
add.s32 %r1366, %r694, %r696;
and.b32 %r697, %r683, 65535;
shr.u32 %r698, %r683, 16;
mad.lo.s32 %r699, %r697, 36969, %r698;
and.b32 %r700, %r686, 65535;
shr.u32 %r701, %r686, 16;
mad.lo.s32 %r702, %r700, 18000, %r701;
shl.b32 %r703, %r699, 16;
add.s32 %r704, %r703, %r702;
shl.b32 %r705, %r694, 17;
xor.b32 %r706, %r705, %r694;
shr.u32 %r707, %r706, 13;
xor.b32 %r708, %r707, %r706;
shl.b32 %r709, %r708, 5;
xor.b32 %r710, %r709, %r708;
mad.lo.s32 %r711, %r695, 69069, 1234567;
xor.b32 %r712, %r704, %r711;
add.s32 %r1370, %r710, %r712;
and.b32 %r713, %r699, 65535;
shr.u32 %r714, %r699, 16;
mad.lo.s32 %r715, %r713, 36969, %r714;
and.b32 %r716, %r702, 65535;
shr.u32 %r717, %r702, 16;
mad.lo.s32 %r718, %r716, 18000, %r717;
shl.b32 %r719, %r715, 16;
add.s32 %r720, %r719, %r718;
shl.b32 %r721, %r710, 17;
xor.b32 %r722, %r721, %r710;
shr.u32 %r723, %r722, 13;
xor.b32 %r724, %r723, %r722;
shl.b32 %r725, %r724, 5;
xor.b32 %r726, %r725, %r724;
mad.lo.s32 %r727, %r711, 69069, 1234567;
xor.b32 %r728, %r720, %r727;
add.s32 %r1362, %r726, %r728;
and.b32 %r729, %r715, 65535;
shr.u32 %r730, %r715, 16;
mad.lo.s32 %r731, %r729, 36969, %r730;
and.b32 %r732, %r718, 65535;
shr.u32 %r733, %r718, 16;
mad.lo.s32 %r734, %r732, 18000, %r733;
shl.b32 %r735, %r731, 16;
add.s32 %r736, %r735, %r734;
shl.b32 %r737, %r726, 17;
xor.b32 %r738, %r737, %r726;
shr.u32 %r739, %r738, 13;
xor.b32 %r740, %r739, %r738;
shl.b32 %r741, %r740, 5;
xor.b32 %r742, %r741, %r740;
mad.lo.s32 %r743, %r727, 69069, 1234567;
xor.b32 %r744, %r736, %r743;
add.s32 %r1345, %r742, %r744;
and.b32 %r745, %r731, 65535;
shr.u32 %r746, %r731, 16;
mad.lo.s32 %r747, %r745, 36969, %r746;
and.b32 %r748, %r734, 65535;
shr.u32 %r749, %r734, 16;
mad.lo.s32 %r750, %r748, 18000, %r749;
shl.b32 %r751, %r747, 16;
add.s32 %r752, %r751, %r750;
shl.b32 %r753, %r742, 17;
xor.b32 %r754, %r753, %r742;
shr.u32 %r755, %r754, 13;
xor.b32 %r756, %r755, %r754;
shl.b32 %r757, %r756, 5;
xor.b32 %r758, %r757, %r756;
mad.lo.s32 %r759, %r743, 69069, 1234567;
xor.b32 %r760, %r752, %r759;
add.s32 %r1358, %r758, %r760;
and.b32 %r761, %r747, 65535;
shr.u32 %r762, %r747, 16;
mad.lo.s32 %r763, %r761, 36969, %r762;
and.b32 %r764, %r750, 65535;
shr.u32 %r765, %r750, 16;
mad.lo.s32 %r766, %r764, 18000, %r765;
shl.b32 %r767, %r763, 16;
add.s32 %r768, %r767, %r766;
shl.b32 %r769, %r758, 17;
xor.b32 %r770, %r769, %r758;
shr.u32 %r771, %r770, 13;
xor.b32 %r772, %r771, %r770;
shl.b32 %r773, %r772, 5;
xor.b32 %r774, %r773, %r772;
mad.lo.s32 %r775, %r759, 69069, 1234567;
xor.b32 %r776, %r768, %r775;
add.s32 %r1344, %r774, %r776;
and.b32 %r777, %r763, 65535;
and.b32 %r778, %r766, 65535;
shr.u32 %r779, %r766, 16;
mad.lo.s32 %r780, %r778, 18000, %r779;
mad.lo.s32 %r781, %r777, -1872166912, %r763;
and.b32 %r782, %r781, -65536;
add.s32 %r783, %r782, %r780;
shl.b32 %r784, %r774, 17;
xor.b32 %r785, %r784, %r774;
shr.u32 %r786, %r785, 13;
xor.b32 %r787, %r786, %r785;
shl.b32 %r788, %r787, 5;
xor.b32 %r789, %r788, %r787;
mad.lo.s32 %r790, %r775, 69069, 1234567;
xor.b32 %r791, %r783, %r790;
add.s32 %r1363, %r789, %r791;
setp.eq.s16	%p6, %rs2, 0;
mov.u32 %r1305, %r263;
mov.u32 %r1338, %r263;
@%p6 bra BB0_6;
bra.uni BB0_5;

BB0_6:
.pragma "nounroll";
mov.u32 %r1259, -1;
mov.u32 %r1256, 4127;
and.b32 %r1018, %r1338, 15;
mov.u32 %r957, 15;
shfl.sync.idx.b32 %r1021|%p9, %r1339, %r1018, %r1256, %r1259;
mul.wide.u32 %rd17, %r1021, -33293311;
shr.u64 %rd18, %rd17, 54;
cvt.u32.u64	%r1022, %rd18;
mul.lo.s32 %r1023, %r1022, 4227071;
sub.s32 %r1024, %r1021, %r1023;
shl.b32 %r1025, %r1024, 4;
mov.u32 %r981, 4;
xor.b32 %r1026, %r1338, %r3;
and.b32 %r1027, %r1026, 15;
add.s32 %r1028, %r1025, %r1027;
mul.wide.u32 %rd19, %r1028, 16;
add.s64 %rd20, %rd1, %rd19;
ld.global.v4.u32 {%r1029, %r1030, %r1031, %r1032}, [%rd20];
mov.u32 %r969, 2;
shl.b32 %r1037, %r1365, 2;
and.b32 %r1038, %r1037, 16380;
mov.u32 %r1039, _ZZ14progpow_searchm8hash32_tmPK5dag_tP14search_resultsbE5c_dag;
add.s32 %r1040, %r1039, %r1038;
ld.shared.u32 %r1041, [%r1040];
mov.u32 %r954, 17;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r954, 0x1f;
shr.b32 lhs, %r1370, roff;
sub.u32 loff, 32, roff;
shl.b32 %r949, %r1370, loff;
add.u32 %r949, %r949, lhs;
}


	xor.b32 %r1370, %r949, %r1041;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r954, 0x1f;
shl.b32 lhs, %r1369, loff;
sub.u32 roff, 32, loff;
shr.b32 %r952, %r1369, roff;
add.u32 %r952, lhs, %r952;
}


	xor.b32 %r1042, %r1346, %r1340;
xor.b32 %r1369, %r1042, %r952;
shl.b32 %r1043, %r1351, 2;
and.b32 %r1044, %r1043, 16380;
add.s32 %r1045, %r1039, %r1044;
ld.shared.u32 %r1046, [%r1045];

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r957, 0x1f;
shl.b32 lhs, %r1368, loff;
sub.u32 roff, 32, loff;
shr.b32 %r955, %r1368, roff;
add.u32 %r955, lhs, %r955;
}


	xor.b32 %r1368, %r955, %r1046;
xor.b32 %r1047, %r1357, %r1355;
mad.lo.s32 %r1367, %r1367, 33, %r1047;
shl.b32 %r1048, %r1358, 2;
and.b32 %r1049, %r1048, 16380;
add.s32 %r1050, %r1039, %r1049;
ld.shared.u32 %r1051, [%r1050];
xor.b32 %r1052, %r1366, %r1051;
mul.lo.s32 %r1366, %r1052, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1365, 0x1f;
shl.b32 lhs, %r1341, loff;
sub.u32 roff, 32, loff;
shr.b32 %r958, %r1341, roff;
add.u32 %r958, lhs, %r958;
}


	mov.u32 %r1014, 13;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r1014, 0x1f;
shr.b32 lhs, %r1365, roff;
sub.u32 loff, 32, roff;
shl.b32 %r961, %r1365, loff;
add.u32 %r961, %r961, lhs;
}


	xor.b32 %r1365, %r961, %r958;
shl.b32 %r1053, %r1356, 2;
and.b32 %r1054, %r1053, 16380;
add.s32 %r1055, %r1039, %r1054;
ld.shared.u32 %r1056, [%r1055];
mov.u32 %r966, 8;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r966, 0x1f;
shl.b32 lhs, %r1364, loff;
sub.u32 roff, 32, loff;
shr.b32 %r964, %r1364, roff;
add.u32 %r964, lhs, %r964;
}


	xor.b32 %r1364, %r964, %r1056;
mul.lo.s32 %r1057, %r1355, %r1347;
xor.b32 %r1058, %r1363, %r1057;
mul.lo.s32 %r1363, %r1058, 33;
shl.b32 %r1059, %r1360, 2;
and.b32 %r1060, %r1059, 16380;
add.s32 %r1061, %r1039, %r1060;
ld.shared.u32 %r1062, [%r1061];

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r969, 0x1f;
shl.b32 lhs, %r1362, loff;
sub.u32 roff, 32, loff;
shr.b32 %r967, %r1362, roff;
add.u32 %r967, lhs, %r967;
}


	xor.b32 %r1362, %r967, %r1062;
popc.b32 %r1063, %r1359;
popc.b32 %r1064, %r1345;
add.s32 %r1065, %r1063, %r1064;
mad.lo.s32 %r1361, %r1361, 33, %r1065;
shl.b32 %r1066, %r1350, 2;
and.b32 %r1067, %r1066, 16380;
add.s32 %r1068, %r1039, %r1067;
ld.shared.u32 %r1069, [%r1068];
mov.u32 %r972, 28;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r972, 0x1f;
shr.b32 lhs, %r1360, roff;
sub.u32 loff, 32, roff;
shl.b32 %r970, %r1360, loff;
add.u32 %r970, %r970, lhs;
}


	xor.b32 %r1360, %r970, %r1069;
xor.b32 %r1070, %r1365, %r1363;
xor.b32 %r1071, %r1070, %r1359;
mul.lo.s32 %r1359, %r1071, 33;
shl.b32 %r1072, %r1347, 2;
and.b32 %r1073, %r1072, 16380;
add.s32 %r1074, %r1039, %r1073;
ld.shared.u32 %r1075, [%r1074];
mov.u32 %r975, 10;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r975, 0x1f;
shr.b32 lhs, %r1358, roff;
sub.u32 loff, 32, roff;
shl.b32 %r973, %r1358, loff;
add.u32 %r973, %r973, lhs;
}


	xor.b32 %r1358, %r973, %r1075;
popc.b32 %r1076, %r1365;
popc.b32 %r1077, %r1341;
add.s32 %r1078, %r1076, %r1077;
mad.lo.s32 %r1357, %r1357, 33, %r1078;
shl.b32 %r1079, %r1354, 2;
and.b32 %r1080, %r1079, 16380;
add.s32 %r1081, %r1039, %r1080;
ld.shared.u32 %r1082, [%r1081];
xor.b32 %r1083, %r1356, %r1082;
mul.lo.s32 %r1356, %r1083, 33;
min.u32 %r1084, %r1357, %r1342;
mad.lo.s32 %r1355, %r1355, 33, %r1084;
shl.b32 %r1085, %r1359, 2;
and.b32 %r1086, %r1085, 16380;
add.s32 %r1087, %r1039, %r1086;
ld.shared.u32 %r1088, [%r1087];
xor.b32 %r1089, %r1354, %r1088;
mul.lo.s32 %r1354, %r1089, 33;
mul.lo.s32 %r1090, %r1357, %r1339;
mov.u32 %r978, 23;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r978, 0x1f;
shr.b32 lhs, %r1353, roff;
sub.u32 loff, 32, roff;
shl.b32 %r976, %r1353, loff;
add.u32 %r976, %r976, lhs;
}


	xor.b32 %r1353, %r976, %r1090;
shl.b32 %r1091, %r1369, 2;
and.b32 %r1092, %r1091, 16380;
add.s32 %r1093, %r1039, %r1092;
ld.shared.u32 %r1094, [%r1093];
mad.lo.s32 %r1352, %r1352, 33, %r1094;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r981, 0x1f;
shr.b32 lhs, %r1351, roff;
sub.u32 loff, 32, roff;
shl.b32 %r979, %r1351, loff;
add.u32 %r979, %r979, lhs;
}


	min.u32 %r1095, %r1348, %r1345;
xor.b32 %r1351, %r979, %r1095;
shl.b32 %r1096, %r1339, 2;
and.b32 %r1097, %r1096, 16380;
add.s32 %r1098, %r1039, %r1097;
ld.shared.u32 %r1099, [%r1098];
xor.b32 %r1100, %r1350, %r1099;
mul.lo.s32 %r1350, %r1100, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1369, 0x1f;
shl.b32 lhs, %r1348, loff;
sub.u32 roff, 32, loff;
shr.b32 %r982, %r1348, roff;
add.u32 %r982, lhs, %r982;
}


	mov.u32 %r987, 5;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r987, 0x1f;
shr.b32 lhs, %r1349, roff;
sub.u32 loff, 32, roff;
shl.b32 %r985, %r1349, loff;
add.u32 %r985, %r985, lhs;
}


	xor.b32 %r1349, %r985, %r982;
min.u32 %r1101, %r1370, %r1341;
mad.lo.s32 %r1348, %r1348, 33, %r1101;
min.u32 %r1102, %r1353, %r1344;
mov.u32 %r990, 26;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r990, 0x1f;
shl.b32 lhs, %r1347, loff;
sub.u32 roff, 32, loff;
shr.b32 %r988, %r1347, roff;
add.u32 %r988, lhs, %r988;
}


	xor.b32 %r1347, %r988, %r1102;
xor.b32 %r1103, %r1355, %r1365;
mov.u32 %r993, 30;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r993, 0x1f;
shl.b32 lhs, %r1346, loff;
sub.u32 roff, 32, loff;
shr.b32 %r991, %r1346, roff;
add.u32 %r991, lhs, %r991;
}


	xor.b32 %r1346, %r1103, %r991;
min.u32 %r1104, %r1347, %r1340;
mov.u32 %r1002, 31;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1002, 0x1f;
shl.b32 lhs, %r1345, loff;
sub.u32 roff, 32, loff;
shr.b32 %r994, %r1345, roff;
add.u32 %r994, lhs, %r994;
}


	xor.b32 %r1345, %r994, %r1104;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1369, 0x1f;
shl.b32 lhs, %r1365, loff;
sub.u32 roff, 32, loff;
shr.b32 %r997, %r1365, roff;
add.u32 %r997, lhs, %r997;
}


	
	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1002, 0x1f;
shl.b32 lhs, %r1344, loff;
sub.u32 roff, 32, loff;
shr.b32 %r1000, %r1344, roff;
add.u32 %r1000, lhs, %r1000;
}


	xor.b32 %r1344, %r1000, %r997;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1362, 0x1f;
shl.b32 lhs, %r1345, loff;
sub.u32 roff, 32, loff;
shr.b32 %r1003, %r1345, roff;
add.u32 %r1003, lhs, %r1003;
}


	mad.lo.s32 %r1343, %r1343, 33, %r1003;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1345, 0x1f;
shl.b32 lhs, %r1344, loff;
sub.u32 roff, 32, loff;
shr.b32 %r1006, %r1344, roff;
add.u32 %r1006, lhs, %r1006;
}


	mov.u32 %r1017, 12;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1017, 0x1f;
shl.b32 lhs, %r1342, loff;
sub.u32 roff, 32, loff;
shr.b32 %r1009, %r1342, roff;
add.u32 %r1009, lhs, %r1009;
}


	xor.b32 %r1342, %r1009, %r1006;
mad.lo.s32 %r1016, %r1339, 33, %r1029;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1014, 0x1f;
shl.b32 lhs, %r1341, loff;
sub.u32 roff, 32, loff;
shr.b32 %r1012, %r1341, roff;
add.u32 %r1012, lhs, %r1012;
}


	xor.b32 %r1341, %r1012, %r1030;
xor.b32 %r1105, %r1340, %r1031;
mul.lo.s32 %r1340, %r1105, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r1017, 0x1f;
shr.b32 lhs, %r1016, roff;
sub.u32 loff, 32, roff;
shl.b32 %r1015, %r1016, loff;
add.u32 %r1015, %r1015, lhs;
}


	xor.b32 %r1339, %r1015, %r1032;
add.s32 %r1338, %r1338, 1;
setp.ne.s32	%p10, %r1338, 64;
@%p10 bra BB0_6;
bra.uni BB0_7;

BB0_5:
.pragma "nounroll";
mov.u32 %r1257, -1;
mov.u32 %r1251, 4127;
and.b32 %r861, %r1305, 15;
mov.u32 %r800, 15;
shfl.sync.idx.b32 %r864|%p7, %r1339, %r861, %r1251, %r1257;
mul.wide.u32 %rd13, %r864, -33293311;
shr.u64 %rd14, %rd13, 54;
cvt.u32.u64	%r865, %rd14;
mul.lo.s32 %r866, %r865, 4227071;
sub.s32 %r867, %r864, %r866;
shl.b32 %r868, %r867, 4;
mov.u32 %r824, 4;
xor.b32 %r869, %r1305, %r3;
and.b32 %r870, %r869, 15;
add.s32 %r871, %r868, %r870;
mul.wide.u32 %rd15, %r871, 16;
add.s64 %rd16, %rd1, %rd15;
ld.global.v4.u32 {%r872, %r873, %r874, %r875}, [%rd16];
mov.u32 %r812, 2;
membar.cta;
shl.b32 %r880, %r1365, 2;
and.b32 %r881, %r880, 16380;
mov.u32 %r882, _ZZ14progpow_searchm8hash32_tmPK5dag_tP14search_resultsbE5c_dag;
add.s32 %r883, %r882, %r881;
ld.shared.u32 %r884, [%r883];
mov.u32 %r797, 17;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r797, 0x1f;
shr.b32 lhs, %r1370, roff;
sub.u32 loff, 32, roff;
shl.b32 %r792, %r1370, loff;
add.u32 %r792, %r792, lhs;
}


	xor.b32 %r1370, %r792, %r884;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r797, 0x1f;
shl.b32 lhs, %r1369, loff;
sub.u32 roff, 32, loff;
shr.b32 %r795, %r1369, roff;
add.u32 %r795, lhs, %r795;
}


	xor.b32 %r885, %r1346, %r1340;
xor.b32 %r1369, %r885, %r795;
shl.b32 %r886, %r1351, 2;
and.b32 %r887, %r886, 16380;
add.s32 %r888, %r882, %r887;
ld.shared.u32 %r889, [%r888];

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r800, 0x1f;
shl.b32 lhs, %r1368, loff;
sub.u32 roff, 32, loff;
shr.b32 %r798, %r1368, roff;
add.u32 %r798, lhs, %r798;
}


	xor.b32 %r1368, %r798, %r889;
xor.b32 %r890, %r1357, %r1355;
mad.lo.s32 %r1367, %r1367, 33, %r890;
shl.b32 %r891, %r1358, 2;
and.b32 %r892, %r891, 16380;
add.s32 %r893, %r882, %r892;
ld.shared.u32 %r894, [%r893];
xor.b32 %r895, %r1366, %r894;
mul.lo.s32 %r1366, %r895, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1365, 0x1f;
shl.b32 lhs, %r1341, loff;
sub.u32 roff, 32, loff;
shr.b32 %r801, %r1341, roff;
add.u32 %r801, lhs, %r801;
}


	mov.u32 %r857, 13;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r857, 0x1f;
shr.b32 lhs, %r1365, roff;
sub.u32 loff, 32, roff;
shl.b32 %r804, %r1365, loff;
add.u32 %r804, %r804, lhs;
}


	xor.b32 %r1365, %r804, %r801;
shl.b32 %r896, %r1356, 2;
and.b32 %r897, %r896, 16380;
add.s32 %r898, %r882, %r897;
ld.shared.u32 %r899, [%r898];
mov.u32 %r809, 8;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r809, 0x1f;
shl.b32 lhs, %r1364, loff;
sub.u32 roff, 32, loff;
shr.b32 %r807, %r1364, roff;
add.u32 %r807, lhs, %r807;
}


	xor.b32 %r1364, %r807, %r899;
mul.lo.s32 %r900, %r1355, %r1347;
xor.b32 %r901, %r1363, %r900;
mul.lo.s32 %r1363, %r901, 33;
shl.b32 %r902, %r1360, 2;
and.b32 %r903, %r902, 16380;
add.s32 %r904, %r882, %r903;
ld.shared.u32 %r905, [%r904];

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r812, 0x1f;
shl.b32 lhs, %r1362, loff;
sub.u32 roff, 32, loff;
shr.b32 %r810, %r1362, roff;
add.u32 %r810, lhs, %r810;
}


	xor.b32 %r1362, %r810, %r905;
popc.b32 %r906, %r1359;
popc.b32 %r907, %r1345;
add.s32 %r908, %r906, %r907;
mad.lo.s32 %r1361, %r1361, 33, %r908;
shl.b32 %r909, %r1350, 2;
and.b32 %r910, %r909, 16380;
add.s32 %r911, %r882, %r910;
ld.shared.u32 %r912, [%r911];
mov.u32 %r815, 28;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r815, 0x1f;
shr.b32 lhs, %r1360, roff;
sub.u32 loff, 32, roff;
shl.b32 %r813, %r1360, loff;
add.u32 %r813, %r813, lhs;
}


	xor.b32 %r1360, %r813, %r912;
xor.b32 %r913, %r1365, %r1363;
xor.b32 %r914, %r913, %r1359;
mul.lo.s32 %r1359, %r914, 33;
shl.b32 %r915, %r1347, 2;
and.b32 %r916, %r915, 16380;
add.s32 %r917, %r882, %r916;
ld.shared.u32 %r918, [%r917];
mov.u32 %r818, 10;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r818, 0x1f;
shr.b32 lhs, %r1358, roff;
sub.u32 loff, 32, roff;
shl.b32 %r816, %r1358, loff;
add.u32 %r816, %r816, lhs;
}


	xor.b32 %r1358, %r816, %r918;
popc.b32 %r919, %r1365;
popc.b32 %r920, %r1341;
add.s32 %r921, %r919, %r920;
mad.lo.s32 %r1357, %r1357, 33, %r921;
shl.b32 %r922, %r1354, 2;
and.b32 %r923, %r922, 16380;
add.s32 %r924, %r882, %r923;
ld.shared.u32 %r925, [%r924];
xor.b32 %r926, %r1356, %r925;
mul.lo.s32 %r1356, %r926, 33;
min.u32 %r927, %r1357, %r1342;
mad.lo.s32 %r1355, %r1355, 33, %r927;
shl.b32 %r928, %r1359, 2;
and.b32 %r929, %r928, 16380;
add.s32 %r930, %r882, %r929;
ld.shared.u32 %r931, [%r930];
xor.b32 %r932, %r1354, %r931;
mul.lo.s32 %r1354, %r932, 33;
mul.lo.s32 %r933, %r1357, %r1339;
mov.u32 %r821, 23;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r821, 0x1f;
shr.b32 lhs, %r1353, roff;
sub.u32 loff, 32, roff;
shl.b32 %r819, %r1353, loff;
add.u32 %r819, %r819, lhs;
}


	xor.b32 %r1353, %r819, %r933;
shl.b32 %r934, %r1369, 2;
and.b32 %r935, %r934, 16380;
add.s32 %r936, %r882, %r935;
ld.shared.u32 %r937, [%r936];
mad.lo.s32 %r1352, %r1352, 33, %r937;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r824, 0x1f;
shr.b32 lhs, %r1351, roff;
sub.u32 loff, 32, roff;
shl.b32 %r822, %r1351, loff;
add.u32 %r822, %r822, lhs;
}


	min.u32 %r938, %r1348, %r1345;
xor.b32 %r1351, %r822, %r938;
shl.b32 %r939, %r1339, 2;
and.b32 %r940, %r939, 16380;
add.s32 %r941, %r882, %r940;
ld.shared.u32 %r942, [%r941];
xor.b32 %r943, %r1350, %r942;
mul.lo.s32 %r1350, %r943, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1369, 0x1f;
shl.b32 lhs, %r1348, loff;
sub.u32 roff, 32, loff;
shr.b32 %r825, %r1348, roff;
add.u32 %r825, lhs, %r825;
}


	mov.u32 %r830, 5;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r830, 0x1f;
shr.b32 lhs, %r1349, roff;
sub.u32 loff, 32, roff;
shl.b32 %r828, %r1349, loff;
add.u32 %r828, %r828, lhs;
}


	xor.b32 %r1349, %r828, %r825;
min.u32 %r944, %r1370, %r1341;
mad.lo.s32 %r1348, %r1348, 33, %r944;
min.u32 %r945, %r1353, %r1344;
mov.u32 %r833, 26;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r833, 0x1f;
shl.b32 lhs, %r1347, loff;
sub.u32 roff, 32, loff;
shr.b32 %r831, %r1347, roff;
add.u32 %r831, lhs, %r831;
}


	xor.b32 %r1347, %r831, %r945;
xor.b32 %r946, %r1355, %r1365;
mov.u32 %r836, 30;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r836, 0x1f;
shl.b32 lhs, %r1346, loff;
sub.u32 roff, 32, loff;
shr.b32 %r834, %r1346, roff;
add.u32 %r834, lhs, %r834;
}


	xor.b32 %r1346, %r946, %r834;
min.u32 %r947, %r1347, %r1340;
mov.u32 %r845, 31;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r845, 0x1f;
shl.b32 lhs, %r1345, loff;
sub.u32 roff, 32, loff;
shr.b32 %r837, %r1345, roff;
add.u32 %r837, lhs, %r837;
}


	xor.b32 %r1345, %r837, %r947;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1369, 0x1f;
shl.b32 lhs, %r1365, loff;
sub.u32 roff, 32, loff;
shr.b32 %r840, %r1365, roff;
add.u32 %r840, lhs, %r840;
}


	
	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r845, 0x1f;
shl.b32 lhs, %r1344, loff;
sub.u32 roff, 32, loff;
shr.b32 %r843, %r1344, roff;
add.u32 %r843, lhs, %r843;
}


	xor.b32 %r1344, %r843, %r840;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1362, 0x1f;
shl.b32 lhs, %r1345, loff;
sub.u32 roff, 32, loff;
shr.b32 %r846, %r1345, roff;
add.u32 %r846, lhs, %r846;
}


	mad.lo.s32 %r1343, %r1343, 33, %r846;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r1345, 0x1f;
shl.b32 lhs, %r1344, loff;
sub.u32 roff, 32, loff;
shr.b32 %r849, %r1344, roff;
add.u32 %r849, lhs, %r849;
}


	mov.u32 %r860, 12;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r860, 0x1f;
shl.b32 lhs, %r1342, loff;
sub.u32 roff, 32, loff;
shr.b32 %r852, %r1342, roff;
add.u32 %r852, lhs, %r852;
}


	xor.b32 %r1342, %r852, %r849;
membar.cta;
mad.lo.s32 %r859, %r1339, 33, %r872;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 loff, %r857, 0x1f;
shl.b32 lhs, %r1341, loff;
sub.u32 roff, 32, loff;
shr.b32 %r855, %r1341, roff;
add.u32 %r855, lhs, %r855;
}


	xor.b32 %r1341, %r855, %r873;
xor.b32 %r948, %r1340, %r874;
mul.lo.s32 %r1340, %r948, 33;

	{
.reg .b32 lhs;
.reg .u32 loff,roff;
and.b32 roff, %r860, 0x1f;
shr.b32 lhs, %r859, roff;
sub.u32 loff, 32, roff;
shl.b32 %r858, %r859, loff;
add.u32 %r858, %r858, lhs;
}


	xor.b32 %r1339, %r858, %r875;
add.s32 %r1305, %r1305, 1;
setp.eq.s32	%p8, %r1305, 64;
@%p8 bra BB0_7;
bra.uni BB0_5;

BB0_7:
mov.u32 %r1258, -1;
mov.u32 %r1252, 4127;
xor.b32 %r1106, %r1339, -2128831035;
mul.lo.s32 %r1107, %r1106, 16777619;
xor.b32 %r1108, %r1351, %r1107;
mul.lo.s32 %r1109, %r1108, 16777619;
xor.b32 %r1110, %r1343, %r1109;
mul.lo.s32 %r1111, %r1110, 16777619;
xor.b32 %r1112, %r1346, %r1111;
mul.lo.s32 %r1113, %r1112, 16777619;
xor.b32 %r1114, %r1341, %r1113;
mul.lo.s32 %r1115, %r1114, 16777619;
xor.b32 %r1116, %r1361, %r1115;
mul.lo.s32 %r1117, %r1116, 16777619;
xor.b32 %r1118, %r1356, %r1117;
mul.lo.s32 %r1119, %r1118, 16777619;
xor.b32 %r1120, %r1364, %r1119;
mul.lo.s32 %r1121, %r1120, 16777619;
xor.b32 %r1122, %r1347, %r1121;
mul.lo.s32 %r1123, %r1122, 16777619;
xor.b32 %r1124, %r1369, %r1123;
mul.lo.s32 %r1125, %r1124, 16777619;
xor.b32 %r1126, %r1357, %r1125;
mul.lo.s32 %r1127, %r1126, 16777619;
xor.b32 %r1128, %r1360, %r1127;
mul.lo.s32 %r1129, %r1128, 16777619;
xor.b32 %r1130, %r1365, %r1129;
mul.lo.s32 %r1131, %r1130, 16777619;
xor.b32 %r1132, %r1340, %r1131;
mul.lo.s32 %r1133, %r1132, 16777619;
xor.b32 %r1134, %r1354, %r1133;
mul.lo.s32 %r1135, %r1134, 16777619;
xor.b32 %r1136, %r1368, %r1135;
mul.lo.s32 %r1137, %r1136, 16777619;
xor.b32 %r1138, %r1367, %r1137;
mul.lo.s32 %r1139, %r1138, 16777619;
xor.b32 %r1140, %r1359, %r1139;
mul.lo.s32 %r1141, %r1140, 16777619;
xor.b32 %r1142, %r1350, %r1141;
mul.lo.s32 %r1143, %r1142, 16777619;
xor.b32 %r1144, %r1353, %r1143;
mul.lo.s32 %r1145, %r1144, 16777619;
xor.b32 %r1146, %r1342, %r1145;
mul.lo.s32 %r1147, %r1146, 16777619;
xor.b32 %r1148, %r1349, %r1147;
mul.lo.s32 %r1149, %r1148, 16777619;
xor.b32 %r1150, %r1348, %r1149;
mul.lo.s32 %r1151, %r1150, 16777619;
xor.b32 %r1152, %r1352, %r1151;
mul.lo.s32 %r1153, %r1152, 16777619;
xor.b32 %r1154, %r1355, %r1153;
mul.lo.s32 %r1155, %r1154, 16777619;
xor.b32 %r1156, %r1366, %r1155;
mul.lo.s32 %r1157, %r1156, 16777619;
xor.b32 %r1158, %r1370, %r1157;
mul.lo.s32 %r1159, %r1158, 16777619;
xor.b32 %r1160, %r1362, %r1159;
mul.lo.s32 %r1161, %r1160, 16777619;
xor.b32 %r1162, %r1345, %r1161;
mul.lo.s32 %r1163, %r1162, 16777619;
xor.b32 %r1164, %r1358, %r1163;
mul.lo.s32 %r1165, %r1164, 16777619;
xor.b32 %r1166, %r1344, %r1165;
mul.lo.s32 %r1167, %r1166, 16777619;
xor.b32 %r1168, %r1363, %r1167;
mul.lo.s32 %r1169, %r1168, 16777619;
mov.u32 %r1171, 0;
shfl.sync.idx.b32 %r1173|%p11, %r1169, %r1171, %r1252, %r1258;
xor.b32 %r1174, %r1173, -2128831035;
mul.lo.s32 %r1175, %r1174, 16777619;
mov.u32 %r1176, 1;
shfl.sync.idx.b32 %r1177|%p12, %r1169, %r1176, %r1252, %r1258;
xor.b32 %r1178, %r1177, -2128831035;
mul.lo.s32 %r1179, %r1178, 16777619;
mov.u32 %r1180, 2;
shfl.sync.idx.b32 %r1181|%p13, %r1169, %r1180, %r1252, %r1258;
xor.b32 %r1182, %r1181, -2128831035;
mul.lo.s32 %r1183, %r1182, 16777619;
mov.u32 %r1184, 3;
shfl.sync.idx.b32 %r1185|%p14, %r1169, %r1184, %r1252, %r1258;
xor.b32 %r1186, %r1185, -2128831035;
mul.lo.s32 %r1187, %r1186, 16777619;
mov.u32 %r1188, 4;
shfl.sync.idx.b32 %r1189|%p15, %r1169, %r1188, %r1252, %r1258;
xor.b32 %r1190, %r1189, -2128831035;
mul.lo.s32 %r1191, %r1190, 16777619;
mov.u32 %r1192, 5;
shfl.sync.idx.b32 %r1193|%p16, %r1169, %r1192, %r1252, %r1258;
xor.b32 %r1194, %r1193, -2128831035;
mul.lo.s32 %r1195, %r1194, 16777619;
mov.u32 %r1196, 6;
shfl.sync.idx.b32 %r1197|%p17, %r1169, %r1196, %r1252, %r1258;
xor.b32 %r1198, %r1197, -2128831035;
mul.lo.s32 %r1199, %r1198, 16777619;
mov.u32 %r1200, 7;
shfl.sync.idx.b32 %r1201|%p18, %r1169, %r1200, %r1252, %r1258;
xor.b32 %r1202, %r1201, -2128831035;
mul.lo.s32 %r1203, %r1202, 16777619;
mov.u32 %r1204, 8;
shfl.sync.idx.b32 %r1205|%p19, %r1169, %r1204, %r1252, %r1258;
xor.b32 %r215, %r1205, %r1175;
mov.u32 %r1206, 9;
shfl.sync.idx.b32 %r1207|%p20, %r1169, %r1206, %r1252, %r1258;
xor.b32 %r216, %r1207, %r1179;
mov.u32 %r1208, 10;
shfl.sync.idx.b32 %r1209|%p21, %r1169, %r1208, %r1252, %r1258;
xor.b32 %r217, %r1209, %r1183;
mov.u32 %r1210, 11;
shfl.sync.idx.b32 %r1211|%p22, %r1169, %r1210, %r1252, %r1258;
xor.b32 %r218, %r1211, %r1187;
mov.u32 %r1212, 12;
shfl.sync.idx.b32 %r1213|%p23, %r1169, %r1212, %r1252, %r1258;
xor.b32 %r219, %r1213, %r1191;
mov.u32 %r1214, 13;
shfl.sync.idx.b32 %r1215|%p24, %r1169, %r1214, %r1252, %r1258;
xor.b32 %r220, %r1215, %r1195;
mov.u32 %r1216, 14;
shfl.sync.idx.b32 %r1217|%p25, %r1169, %r1216, %r1252, %r1258;
xor.b32 %r221, %r1217, %r1199;
mov.u32 %r1218, 15;
shfl.sync.idx.b32 %r1219|%p26, %r1169, %r1218, %r1252, %r1258;
xor.b32 %r222, %r1219, %r1203;
setp.ne.s32	%p27, %r1272, %r4;
@%p27 bra BB0_9;

mul.lo.s32 %r1378, %r222, 16777619;
mul.lo.s32 %r1377, %r221, 16777619;
mul.lo.s32 %r1376, %r220, 16777619;
mul.lo.s32 %r1375, %r219, 16777619;
mul.lo.s32 %r1371, %r218, 16777619;
mul.lo.s32 %r1372, %r217, 16777619;
mul.lo.s32 %r1373, %r216, 16777619;
mul.lo.s32 %r1374, %r215, 16777619;

BB0_9:
add.s32 %r1272, %r1272, 1;
setp.lt.u32	%p28, %r1272, 16;
@%p28 bra BB0_4;

ld.param.u64 %rd51, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_2];
setp.eq.s64	%p29, %rd51, 0;
@%p29 bra BB0_16;

ld.param.u64 %rd57, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_4];
cvta.to.global.u64 %rd56, %rd57;
atom.global.inc.u32 %r240, [%rd56], -1;
setp.gt.u32	%p30, %r240, 65535;
@%p30 bra BB0_16;

ld.param.u64 %rd59, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_4];
cvta.to.global.u64 %rd58, %rd59;
cvt.u64.u32	%rd3, %r240;
mul.wide.u32 %rd22, %r240, 4;
mov.u64 %rd23, NVM_log;
cvta.global.u64 %rd24, %rd23;
add.s64 %rd21, %rd24, %rd22;
mul.wide.u32 %rd25, %r240, 36;
add.s64 %rd26, %rd58, %rd25;
add.s64 %rd4, %rd26, 4;
ld.global.u32 %r1220, [%rd26+4];

	st.global.u32 [%rd21], %r1220;

	
	membar.gl;

	bar.sync 0;
mov.u32 %r1253, %ntid.x;
mov.u32 %r1221, %tid.y;
mad.lo.s32 %r241, %r1221, %r1253, %r3;
neg.s32 %r1222, %r1253;
mov.u32 %r1223, %tid.z;
mul.lo.s32 %r1224, %r1223, %r1222;
mov.u32 %r1225, %ntid.y;
mul.lo.s32 %r242, %r1224, %r1225;
setp.ne.s32	%p31, %r241, %r242;
@%p31 bra BB0_14;

mov.u64 %rd55, 0;
mov.u32 %r1255, %ctaid.x;
mov.u32 %r1228, %ctaid.y;
mov.u32 %r1229, %nctaid.y;
mov.u32 %r1230, %ctaid.z;
mad.lo.s32 %r1231, %r1229, %r1230, %r1228;
mov.u32 %r1232, %nctaid.x;
mad.lo.s32 %r1233, %r1231, %r1232, %r1255;
mul.wide.u32 %rd30, %r1233, 4;
mov.u64 %rd31, NVM_flag;
cvta.global.u64 %rd32, %rd31;
add.s64 %rd28, %rd32, %rd30;

	st.global.s32 [%rd28], %r1176;

	
	st.global.u32.cs [%rd28], %r1171;

	
	membar.gl;

	mov.f32 %f1, 0f00000000;

	st.global.f32.wb [%rd55], %f1;

	
	membar.gl;


BB0_14:
mov.u32 %r1262, %ctaid.x;
mov.u32 %r1261, %ntid.x;
mad.lo.s32 %r1260, %r1261, %r1262, %r3;
ld.param.u64 %rd53, [_Z14progpow_searchm8hash32_tmPK5dag_tP14search_resultsb_param_4];
mov.u64 %rd52, 0;
setp.eq.s32	%p1, %r241, %r242;
st.global.u32 [%rd4], %r1260;
mul.lo.s64 %rd43, %rd3, 36;
add.s64 %rd44, %rd53, %rd43;
add.s64 %rd33, %rd44, 4;

	st.global.u32.cs [%rd33], %r1171;

	st.global.u32 [%rd4+4], %r1374;
add.s64 %rd34, %rd44, 8;

	st.global.u32.cs [%rd34], %r1171;

	st.global.u32 [%rd4+8], %r1373;
add.s64 %rd35, %rd44, 12;

	st.global.u32.cs [%rd35], %r1171;

	st.global.u32 [%rd4+12], %r1372;
add.s64 %rd36, %rd44, 16;

	st.global.u32.cs [%rd36], %r1171;

	st.global.u32 [%rd4+16], %r1371;
add.s64 %rd37, %rd44, 20;

	st.global.u32.cs [%rd37], %r1171;

	st.global.u32 [%rd4+20], %r1375;
add.s64 %rd38, %rd44, 24;

	st.global.u32.cs [%rd38], %r1171;

	st.global.u32 [%rd4+24], %r1376;
add.s64 %rd39, %rd44, 28;

	st.global.u32.cs [%rd39], %r1171;

	st.global.u32 [%rd4+28], %r1377;
add.s64 %rd40, %rd44, 32;

	st.global.u32.cs [%rd40], %r1171;

	st.global.u32 [%rd4+32], %r1378;
add.s64 %rd41, %rd44, 36;

	st.global.u32.cs [%rd41], %r1171;

	
	membar.gl;

	mov.f32 %f2, 0f00000000;

	st.global.f32.wb [%rd52], %f2;

	
	membar.gl;

	bar.sync 0;
@!%p1 bra BB0_16;
bra.uni BB0_15;

BB0_15:
mov.u64 %rd54, 0;
mov.u32 %r1254, %ctaid.x;
mov.u32 %r1245, %ctaid.y;
mov.u32 %r1246, %nctaid.y;
mov.u32 %r1247, %ctaid.z;
mad.lo.s32 %r1248, %r1246, %r1247, %r1245;
mov.u32 %r1249, %nctaid.x;
mad.lo.s32 %r1250, %r1248, %r1249, %r1254;
mul.wide.u32 %rd48, %r1250, 4;
mov.u64 %rd49, NVM_flag;
cvta.global.u64 %rd50, %rd49;
add.s64 %rd46, %rd50, %rd48;

	st.global.s32 [%rd46], %r1180;

	
	st.global.u32.cs [%rd46], %r1171;

	
	membar.gl;

	
	st.global.f32.wb [%rd54], %f2;

	
	membar.gl;


BB0_16:
ret;
}


